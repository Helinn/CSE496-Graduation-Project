{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this python file is used to construct the fake data for the model\"\"\"\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import Tweet as tweet\n",
    "from datetime import datetime\n",
    "\n",
    "from networkx import *\n",
    "import networkx.algorithms as nxalg\n",
    "\n",
    "def read_data_from_database(script):\n",
    "    mydb = mysql.connector.connect(\n",
    "        user = \"root\",\n",
    "        password = \"D12345\",\n",
    "        host = \"localhost\",\n",
    "        database = \"tweetermysql_2018-07-30\"\n",
    "    )\n",
    "\n",
    "    my_cursor = mydb.cursor()\n",
    "\n",
    "    my_cursor.execute(script)\n",
    "\n",
    "    my_result = my_cursor.fetchall()\n",
    "    \n",
    "    data = list()\n",
    "    \n",
    "    for item in my_result:\n",
    "        u, m_data, date, section = item\n",
    "        t = tweet.Tweet(u,section,m_data,datetime.strptime(date,'%Y-%m-%d'))\n",
    "        data.append(t)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_word_id_dictionary(tweets):\n",
    "    word_id_dict = {}\n",
    "    id = 0\n",
    "    for tweet in tweets:\n",
    "        if not word_id_dict.get(tweet.user):\n",
    "            word_id_dict[tweet.user] = id\n",
    "            id += 1 \n",
    "        if not word_id_dict.get(datetime.strftime(tweet.date,'%Y-%m-%d')):\n",
    "            word_id_dict[datetime.strftime(tweet.date,'%Y-%m-%d')] = id\n",
    "            monthFormat = \"{month}.{year}\".format(month=tweet.date.month,year=tweet.date.year)\n",
    "            dayFormat = \"{day}.{month}.{year}\".format(day=tweet.date.day,month=tweet.date.month,year=tweet.date.year)\n",
    "            word_id_dict[monthFormat] = id + 1\n",
    "            word_id_dict[dayFormat] = id + 2\n",
    "            id += 3\n",
    "        for word in tweet.text.split():\n",
    "            if not word_id_dict.get(word):\n",
    "                word_id_dict[word] = id\n",
    "                id += 1\n",
    "    \n",
    "    return word_id_dict\n",
    "def find_max_node_size_for_tweet_text(tweets):\n",
    "    max_node_size = len(tweets[0].text.split())\n",
    "    #print(max_node_size, tweets[0].text.split())\n",
    "    for tweet in tweets:\n",
    "        if max_node_size < len(tweet.text.split()):\n",
    "            max_node_size = len(tweet.text.split())\n",
    "    return max_node_size\n",
    "def create_time_graph(tweet):\n",
    "    G1 = nx.DiGraph()\n",
    "    #for tweet in tweets:\n",
    "    #G1.add_node(word_id_dict[tweet.user])\n",
    "    tweetFormat = str(tweet.Id)\n",
    "    G1.add_node(str(tweet.date.year))\n",
    "    #G1.add_edge(word_id_dict[tweet.user],tweetFormat,weight=1.0)\n",
    "    #G1.add_edge(YEAR_TAG,tweet.date.year,weight=15.0)\n",
    "    #G.add_edge(tweet.date.year,YEAR_TAG,weight=1.0)\n",
    "    for word in tweet.text.split():\n",
    "        G1.add_edge(word_id_dict[word],tweetFormat,weight=1.0)\n",
    "        \n",
    "    monthFormat = \"{month}.{year}\".format(month=tweet.date.month,year=tweet.date.year)\n",
    "\n",
    "    G1.add_edge(str(tweet.date.year),word_id_dict[monthFormat],weight=1.0)\n",
    "    G1.add_edge(word_id_dict[monthFormat],str(tweet.date.year),weight=1.0)\n",
    "\n",
    "    dayFormat = \"{day}.{month}.{year}\".format(day=tweet.date.day,month=tweet.date.month,year=tweet.date.year)\n",
    "    G1.add_edge(word_id_dict[monthFormat],word_id_dict[dayFormat],weight=1.0)\n",
    "    G1.add_edge(word_id_dict[dayFormat],tweetFormat,weight=1.0)\n",
    "    return G1\n",
    "\n",
    "def create_random_graph(tweets, filePath, graph_scale):\n",
    "    \"\"\"\n",
    "\n",
    "    :param type: the graph type\n",
    "    :param filePath: the output file path\n",
    "    :param numberOfCase: the number of examples\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open(filePath, \"w+\", encoding='utf-8') as f:\n",
    "        degree = 0.0\n",
    "        for i in range(len(tweets)):\n",
    "            info = {}\n",
    "            graph_node_size = graph_scale\n",
    "            graph_real_node_size = graph_scale\n",
    "            edge_prob = 0.3\n",
    "\n",
    "            edge_count = 0.0\n",
    "\n",
    "            graph = create_time_graph(tweets[i])\n",
    "            #graph = nx.convert_node_labels_to_integers(graph,first_label=0)\n",
    "            #graph = nx.DiGraph(),\n",
    "            k = len(graph.nodes)\n",
    "            graph_real_node_size = k\n",
    "            ancestor = \"\"\n",
    "            if k < graph_scale:\n",
    "                while k <= graph_scale:\n",
    "                    graph.add_node(str(k))\n",
    "                    k+=1\n",
    "\n",
    "            for id in graph.edges:\n",
    "                edge_count += len(graph.edges[id])\n",
    "            graph_node_size = len(graph.nodes)\n",
    "            start = 0\n",
    "            #nodes = list(graph.nodes)\n",
    "            end = len(graph.nodes)-1\n",
    "            #path = nx.shortest_path(graph, nodes[0], nodes[len(graph.nodes)-1])\n",
    "            #paths = [p for p in nx.all_shortest_paths(graph, nodes[0], nodes[len(graph.nodes)-1])]\n",
    "            #if len(path) >= 3 and len(paths) == 1:\n",
    "            #    degree += edge_count / len(graph.nodes)\n",
    "            #    break\n",
    "\n",
    "\n",
    "            adj_list = []\n",
    "            for adj in graph.adjacency():\n",
    "                adj_list.append(list(adj[1].keys()))\n",
    "            g_nodes = []\n",
    "            for node in graph.nodes:\n",
    "                g_nodes.append(node)\n",
    "            #print(adj_list[0])\n",
    "\n",
    "            g_ids = {}\n",
    "            g_ids_features = {}\n",
    "            g_adj = {}\n",
    "            #print(graph_node_size,start,end)\n",
    "            for j in range(graph_node_size):\n",
    "                g_ids[j] = int(g_nodes[j])\n",
    "                if j == start:\n",
    "                    g_ids_features[j] = \"START\"\n",
    "                elif j == end:\n",
    "                    g_ids_features[j] = \"END\"\n",
    "                else:\n",
    "                    #g_ids_features[i] = str(i+10)\n",
    "                    g_ids_features[j] =\"1\"\n",
    "                g_adj[j] = adj_list[j]\n",
    "\n",
    "            # print start, end, path\n",
    "            text = \"START \"+ tweets[i].user + \" END \"\n",
    "            #for id in range(len(path)):\n",
    "            #    text += g_ids_features[nodes[id]] + \" \"\n",
    "\n",
    "            info[\"seq\"] = text.strip()\n",
    "            info[\"g_ids\"] = g_ids\n",
    "            info['g_ids_features'] = g_ids_features\n",
    "            info['g_adj'] = g_adj\n",
    "            f.write((json.dumps(info,ensure_ascii=False)+\"\\n\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    script = 'select ID, MetaData, Date,Section from newsdunya_all_sektorler where Section = \"Otomotiv\" or Section =\"Enerji\" or Section = \"Emlak\" limit 300'\n",
    "    tweets = read_data_from_database(script)\n",
    "    graph_scale = find_max_node_size_for_tweet_text(tweets) + 5 \n",
    "    word_id_dict = create_word_id_dictionary(tweets)\n",
    "    #print(word_id_dict)\n",
    "    create_random_graph(tweets, \"./Graph2Seq/data/no_cycle/train.data\", graph_scale)\n",
    "    script =  ' select ID, MetaData, Date,Section from newsdunya_all_sektorler where Section = \"Otomotiv\" or Section =\"Enerji\" or Section = \"Emlak\" limit 300,300'\n",
    "    tweets = read_data_from_database(script)\n",
    "    word_id_dict = create_word_id_dictionary(tweets)\n",
    "    create_random_graph(tweets, \"./Graph2Seq/data/no_cycle/dev.data\", graph_scale)\n",
    "    create_random_graph(tweets, \"./Graph2Seq/data/no_cycle/test.data\", graph_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
