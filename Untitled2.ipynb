{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this python file is used to construct the fake data for the model\"\"\"\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import Tweet as tweet\n",
    "from datetime import datetime\n",
    "\n",
    "from networkx import *\n",
    "import networkx.algorithms as nxalg\n",
    "\n",
    "def read_data_from_database():\n",
    "    mydb = mysql.connector.connect(\n",
    "        user = \"root\",\n",
    "        password = \"D12345\",\n",
    "        host = \"localhost\",\n",
    "        database = \"tweetermysql_2018-07-30\"\n",
    "    )\n",
    "\n",
    "    my_cursor = mydb.cursor()\n",
    "\n",
    "    my_cursor.execute(' select ID, MetaData, Date, Section from news_2017_01 limit 20')\n",
    "\n",
    "    my_result = my_cursor.fetchall()\n",
    "    \n",
    "    data = list()\n",
    "    \n",
    "    for item in my_result:\n",
    "        u, m_data, date, section = item\n",
    "        t = tweet.Tweet(u,section,m_data,datetime.strptime(date,'%Y-%m-%d'))\n",
    "        data.append(t)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_word_id_dictionary(tweets):\n",
    "    word_id_dict = {}\n",
    "    id = 0\n",
    "    for tweet in tweets:\n",
    "        if not word_id_dict.get(tweet.user):\n",
    "            word_id_dict[tweet.user] = id\n",
    "            id += 1 \n",
    "        if not word_id_dict.get(datetime.strftime(tweet.date,'%Y-%m-%d')):\n",
    "            word_id_dict[datetime.strftime(tweet.date,'%Y-%m-%d')] = id\n",
    "            monthFormat = \"{month}.{year}\".format(month=tweet.date.month,year=tweet.date.year)\n",
    "            dayFormat = \"{day}.{month}.{year}\".format(day=tweet.date.day,month=tweet.date.month,year=tweet.date.year)\n",
    "            word_id_dict[monthFormat] = id + 1\n",
    "            word_id_dict[dayFormat] = id + 2\n",
    "            id += 3 \n",
    "        for word in tweet.text.split():\n",
    "            if not word_id_dict.get(word):\n",
    "                word_id_dict[word] = id\n",
    "                id += 1\n",
    "        #print(tweet.user,tweet.text,datetime.strftime(tweet.date,'%Y-%m-%d'))\n",
    "    \n",
    "    return word_id_dict\n",
    "def create_graph(tweet):\n",
    "    G1 = nx.DiGraph()\n",
    "    #for tweet in tweets:\n",
    "    #G1.add_node(word_id_dict[tweet.user])\n",
    "    tweetFormat = str(tweet.Id)\n",
    "    G1.add_node(tweetFormat)\n",
    "    #G1.add_edge(word_id_dict[tweet.user],tweetFormat,weight=1.0)\n",
    "    for word in tweet.text.split():\n",
    "        G1.add_edge(word_id_dict[word],tweetFormat,weight=1.0)\n",
    "        #print(word)\n",
    "    monthFormat = \"{month}.{year}\".format(month=tweet.date.month,year=tweet.date.year)\n",
    "\n",
    "    G1.add_edge(str(tweet.date.year),word_id_dict[monthFormat],weight=1.0)\n",
    "    G1.add_edge(word_id_dict[monthFormat],str(tweet.date.year),weight=1.0)\n",
    "\n",
    "    dayFormat = \"{day}.{month}.{year}\".format(day=tweet.date.day,month=tweet.date.month,year=tweet.date.year)\n",
    "    G1.add_edge(word_id_dict[monthFormat],word_id_dict[dayFormat],weight=1.0)\n",
    "    G1.add_edge(word_id_dict[dayFormat],tweetFormat,weight=1.0)\n",
    "    return G1\n",
    "\n",
    "def create_random_graph(tweets, filePath, graph_scale):\n",
    "    \"\"\"\n",
    "\n",
    "    :param type: the graph type\n",
    "    :param filePath: the output file path\n",
    "    :param numberOfCase: the number of examples\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open(filePath, \"w+\", encoding='utf-8') as f:\n",
    "        degree = 0.0\n",
    "        for i in range(len(tweets)):\n",
    "            info = {}\n",
    "            graph_node_size = graph_scale\n",
    "            graph_real_node_size = graph_scale\n",
    "            edge_prob = 0.3\n",
    "\n",
    "            edge_count = 0.0\n",
    "\n",
    "            graph = create_graph(tweets[i])\n",
    "            #graph = nx.convert_node_labels_to_integers(graph,first_label=0)\n",
    "            #graph = nx.DiGraph(),\n",
    "            k = len(graph.nodes)\n",
    "            graph_real_node_size = k\n",
    "            ancestor = \"\"\n",
    "            if k < 30:\n",
    "                while k <= 30:\n",
    "                    graph.add_node(str(k))\n",
    "                    k+=1\n",
    "\n",
    "            for id in graph.edges:\n",
    "                edge_count += len(graph.edges[id])\n",
    "            graph_node_size = len(graph.nodes)\n",
    "            start = 0\n",
    "            #nodes = list(graph.nodes)\n",
    "            end = len(graph.nodes)-1\n",
    "            #path = nx.shortest_path(graph, nodes[0], nodes[len(graph.nodes)-1])\n",
    "            #paths = [p for p in nx.all_shortest_paths(graph, nodes[0], nodes[len(graph.nodes)-1])]\n",
    "            #if len(path) >= 3 and len(paths) == 1:\n",
    "            #    degree += edge_count / len(graph.nodes)\n",
    "            #    break\n",
    "\n",
    "\n",
    "            adj_list = []\n",
    "            for adj in graph.adjacency():\n",
    "                adj_list.append(list(adj[1].keys()))\n",
    "            g_nodes = []\n",
    "            for node in graph.nodes:\n",
    "                g_nodes.append(node)\n",
    "            #print(adj_list[0])\n",
    "\n",
    "            g_ids = {}\n",
    "            g_ids_features = {}\n",
    "            g_adj = {}\n",
    "            #print(graph_node_size,start,end)\n",
    "            for j in range(graph_node_size):\n",
    "                g_ids[j] = int(g_nodes[j])\n",
    "                if j == start:\n",
    "                    g_ids_features[j] = \"START\"\n",
    "                elif j == end:\n",
    "                    g_ids_features[j] = \"END\"\n",
    "                else:\n",
    "                    #g_ids_features[i] = str(i+10)\n",
    "                    g_ids_features[j] = str(random.randint(1, end))\n",
    "                g_adj[j] = adj_list[j]\n",
    "\n",
    "            # print start, end, path\n",
    "            \n",
    "            text = \"START \"+ tweets[i].user + \" END \"\n",
    "            \n",
    "            #for id in range(len(path)):\n",
    "            #    text += g_ids_features[nodes[id]] + \" \"\n",
    "\n",
    "            info[\"seq\"] = text.strip()\n",
    "            info[\"g_ids\"] = g_ids\n",
    "            info['g_ids_features'] = g_ids_features\n",
    "            info['g_adj'] = g_adj\n",
    "            f.write((json.dumps(info,ensure_ascii=False)+\"\\n\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
